{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3n1qqThTb5H"
      },
      "source": [
        "# Proyecto Final Bootcamp. Primera Parte\n",
        "\n",
        "El proyecto consiste en un RAG que permitira obtener informaci√≥n precisa sobre datos historicos relacionados con la migracion de Espa√±a a latinoamerica.\n",
        "\n",
        "La primera version se enfoca en lo explicado en:\n",
        "- https://machinelearningmastery.com/building-a-rag-pipeline-with-llama-cpp-in-python/\n",
        "- https://github.com/pixegami/langchain-rag-tutorial\n",
        "\n",
        "A continuaci√≥n se explicara paso a paso la creacion de la primera version de nuestro RAG:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdg8BKDYUHt8"
      },
      "source": [
        "## 1) Instalar librerias requeridas\n",
        "\n",
        "Lista de librerias:\n",
        "- OpenAI: Cargar y ejecutar modelos LLM (Large Language Models) de OpenAI.\n",
        "- Langchain: Gestionar la carga, divisi√≥n, vectorizaci√≥n y consulta de documentos con el LLM.\n",
        "- Chromadb: Guarda la informaci√≥n de los pdfs de una forma que los LLMs lo puedan entender.\n",
        "- Unstructured pdf: Extrae el contenido (texto y estructura) de archivos PDF de forma precisa, permitiendo convertir documentos complejos en fragmentos de texto √∫tiles para los LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wL_RD_QlCnbq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Instalar librerias para construir el RAG\n",
        "!pip install --upgrade langchain langchain-community langchain-openai langchain-chroma chromadb openai \"unstructured[pdf]\"\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACzEuA03zK0c"
      },
      "source": [
        "## 2) Importar librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ozM03uuVzTpZ"
      },
      "outputs": [],
      "source": [
        "# Importar librerias\n",
        "# - Miscelaneos\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from dotenv import load_dotenv\n",
        "import textwrap\n",
        "# - Operar documentos (Leer)\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader, DirectoryLoader\n",
        "# - Operar documentos (Dividir en bloques)\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# - Operar documentos (transformar con embeddings)\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "# - Operar documentos (Guardar)\n",
        "from langchain_chroma import Chroma\n",
        "# - Configurar LLMs\n",
        "from langchain_openai import ChatOpenAI\n",
        "# - Configurar RAG\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import DirectoryLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X) Load Drive"
      ],
      "metadata": {
        "id": "S1I5ToZMh6oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeghVvtjh0uw",
        "outputId": "1ef55d49-b9be-47fd-b1d7-f58c81d6d546"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir ruta donde se encuentra el projecto\n",
        "ruta_principal = \"/content/drive/My Drive/Colab Notebooks/PROYECTO FINAL\""
      ],
      "metadata": {
        "id": "vTzEdhyRiIfz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar variables de entorno\n",
        "load_dotenv(dotenv_path=Path(ruta_principal)/\".env\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCVs0suWjGh9",
        "outputId": "43b3db20-462d-47ac-b7ea-34ee27a9ed69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8mO6R-JbmDd"
      },
      "source": [
        "## 3) Operar los documentos\n",
        "\n",
        "En este paso se leeran y operaran los documentos que se usaran para darle contexto al LLM, es decir para darle informacion precisa al RAG.\n",
        "\n",
        "### 3.1) Cargar documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "obWy-JGCUqJW"
      },
      "outputs": [],
      "source": [
        "# Define ruta donde se encontraran los libros\n",
        "ruta_libros = Path(ruta_principal)/\"Libros\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los libros\n",
        "print(f\"Cargadon documento de la ruta: {ruta_libros} usando UnstructuredPDFLoader...\")\n",
        "# Inicializar lista donde se cargan los documentos\n",
        "documents = []\n",
        "try:\n",
        "    loader = DirectoryLoader(\n",
        "        ruta_libros,\n",
        "        glob=\"**/*.pdf\",\n",
        "        loader_cls=UnstructuredPDFLoader, # <--- Necesario para leer objetos como tablas.\n",
        "        show_progress=True\n",
        "    )\n",
        "    documents = loader.load()\n",
        "    print(f\"\\n{len(documents)} documentos correctamente cargados.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error cargando archivos: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMQWCZzGLBDS",
        "outputId": "32a86808-7faa-4f2a-bd16-4f99fd1bf01d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargadon documento de la ruta: /content/drive/My Drive/Colab Notebooks/PROYECTO FINAL/Libros usando UnstructuredPDFLoader...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [40:45<31:11, 935.64s/it]WARNING:pdfminer.pdfpage:The PDF <_io.BufferedReader name='/content/drive/My Drive/Colab Notebooks/PROYECTO FINAL/Libros/el-exilio-y-la-emigracion-espanola-de-posguerra-en-buenos-aires-1936-1956 (2).pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [41:40<10:18, 618.04s/it]WARNING:pdfminer.pdfpage:The PDF <_io.BufferedReader name='/content/drive/My Drive/Colab Notebooks/PROYECTO FINAL/Libros/la-emigracin-espaola-asistida-a-latinoamrica-19681990-0.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [41:41<00:00, 416.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "6 documentos correctamente cargados.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar titulos\n",
        "for doc in documents:\n",
        "    ruta = doc.metadata.get(\"source\", \"\")\n",
        "    nombre_archivo = os.path.basename(ruta)           # e.g., \"Revolucion_Francesa.pdf\"\n",
        "    titulo = os.path.splitext(nombre_archivo)[0]            # remove \".pdf\"\n",
        "    doc.metadata[\"title\"] = titulo                    # now accessible as doc.metadata[\"title\"]\n",
        "print(f\"\\n T√≠tulos de {len(documents)} documentos correctamente asignados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC80-1nB_dH3",
        "outputId": "609f6c91-e8cc-4c9c-d351-11ff111ca925"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " T√≠tulos de 6 documentos correctamente asignados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2) Dividir documentos en bloques (chunks)"
      ],
      "metadata": {
        "id": "B8TiUtEQLA_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RYNa5Su5l-Dt"
      },
      "outputs": [],
      "source": [
        "# Inicializar metodo para dividir los documentos en bloques\n",
        "# - Tama√±o de los bloques\n",
        "chunk_size=1600\n",
        "# - Tama√±o de solapamiento entre bloques\n",
        "chunk_overlap=400\n",
        "# - Crear separador de texto\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        "    add_start_index=True,\n",
        ")\n",
        "# Dividir los documentos en bloques\n",
        "chunks = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTirOfyPMLSm"
      },
      "source": [
        "## 3.3) Transformar los bloques de texto\n",
        "\n",
        "Generar representaciones num√©ricas (embeddings) de fragmentos de texto utilizando un modelo de OpenAI y almacenarlas en una base de datos vectorial local llamada ChromaDB."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar la herramienta para hacer el embeddings\n",
        "modelo_embedding = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "vCwMiUmYOaFG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZEESRwfTMSYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eec9bd8-545e-455c-a9dd-cb8d107cc36e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando proceso para crear el vector embeddings...\n",
            "Crear nuevo vector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ûï Agregando 3626 nuevos documentos en lotes de 100...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [01:04<00:00,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nuevos documentos agregados y vectorstore actualizado.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Definir la ruta de vector embeddings\n",
        "ruta_vector_embeddings = \"chroma_ve\"\n",
        "# Usar chroma para crear los vector embeddings\n",
        "print(\"Iniciando proceso para crear el vector embeddings...\")\n",
        "# Crear vector\n",
        "print(\"Crear nuevo vector...\")\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=str(ruta_vector_embeddings),\n",
        "    embedding_function=modelo_embedding\n",
        ")\n",
        "# Toca usarlo debido a la cantidad de archivos\n",
        "batch_size = 100\n",
        "# Agregar documentos\n",
        "print(f\"‚ûï Agregando {len(chunks)} nuevos documentos en lotes de {batch_size}...\")\n",
        "for i in tqdm(range(0, len(chunks), batch_size)):\n",
        "    batch = chunks[i:i + batch_size]\n",
        "    vectorstore.add_documents(batch)\n",
        "print(\"\\nNuevos documentos agregados y vectorstore actualizado.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar vector una vez creado\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=str(ruta_vector_embeddings),\n",
        "    embedding_function=modelo_embedding\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYeYc0WoX3vC",
        "outputId": "beb26db3-089d-4ece-a946-85aba4d8b9f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisar\n",
        "try:\n",
        "    num_embeddings = vectorstore._collection.count()\n",
        "    print(f\"Number of embeddings (documents/chunks) in the vector store: {num_embeddings}\")\n",
        "except AttributeError:\n",
        "    print(\"Could not access _collection.count(). Ensure 'vectorstore' is a valid Chroma instance.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while counting embeddings: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbBG3hHOq6BO",
        "outputId": "74a52720-b0e8-4a48-b439-46226699cd71"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of embeddings (documents/chunks) in the vector store: 14504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Configurar LLM"
      ],
      "metadata": {
        "id": "AKNvJlv3ZTvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros del LLM\n",
        "# - Temperature:\n",
        "#     Controla la aleatoriedad de las respuestas del modelo.\n",
        "#     Un valor m√°s bajo (cerca de 0) hace que el modelo sea m√°s determinista,\n",
        "#     Un valor m√°s alto (hasta 1 o m√°s) lo hace m√°s creativo o variable.\n",
        "temperature = 0.2\n",
        "# - Max tokens\n",
        "#     Define el n√∫mero m√°ximo de tokens que puede generar el modelo en una respuesta.\n",
        "#     Cuantos m√°s tokens, m√°s larga puede ser la salida (pero consume m√°s memoria y tiempo).\n",
        "max_tokens=2000\n",
        "# - Verbose\n",
        "#   Indica si quieres ver mensajes detallados en la consola sobre el proceso de inferencia.\n",
        "verbose=False"
      ],
      "metadata": {
        "id": "H-TAUkbiZYth"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n LLM OpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4\", # o \"gpt-3.5-turbo\"\n",
        "    temperature=temperature,\n",
        "    max_tokens=max_tokens,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "NVM5ULriZaEA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzuh3PYViOvc"
      },
      "source": [
        "## 5) Crear el sistema RAG\n",
        "\n",
        "### 5.1) Construir el prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plantilla del prompt usado en el sistema RAG\n",
        "template = \"\"\"\n",
        "Eres un asistente de inteligencia artificial especializado en historia. Respondes preguntas √∫nicamente utilizando el contexto documental proporcionado.\n",
        "\n",
        "Reglas:\n",
        "- No inventes informaci√≥n. Si el contexto no tiene la respuesta, dilo claramente.\n",
        "- S√© espec√≠fico y fundamenta tus respuestas citando fragmentos relevantes del contexto (usa comillas si es posible).\n",
        "- Resume con claridad y precisi√≥n. Evita redundancias.\n",
        "- No incluyas informaci√≥n externa al contexto.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "\n",
        "Respuesta fundamentada √∫nicamente en el contexto anterior:\n",
        "\"\"\"\n",
        "# Crear el prompt\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "zvDX0swNj9lW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2) Crear el pipeline del sistema RAG"
      ],
      "metadata": {
        "id": "m2Lg21PSZsja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar retriever\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "# Pipeline de procesamiento del RAG\n",
        "rag_pipeline = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt}\n",
        ")"
      ],
      "metadata": {
        "id": "qQJ-gFsuZys0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3) Crear funcion para que el usuario pregunte"
      ],
      "metadata": {
        "id": "7uRQhOsBa6xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion que tiene como entrada la pregunta o consulta del usuario.\n",
        "def pregunta_usuario(pregunta):\n",
        "    start_time = time.time()\n",
        "    result = rag_pipeline.invoke({\"query\": pregunta})\n",
        "    end_time = time.time()\n",
        "    print(f\"Pregunta: \\n{pregunta}\")\n",
        "    print(f\"Respuesta:\")\n",
        "    print(textwrap.fill(result['result'], width=80))\n",
        "    print(f\"Tiempo de computo: {end_time - start_time:.2f} segundos\")\n",
        "    print(\"\\n\\nDocumentos Fuente:\")\n",
        "    for doc in result[\"source_documents\"]:\n",
        "        titulo = doc.metadata.get(\"title\", \"Sin t√≠tulo\")\n",
        "        fragmento = doc.page_content.strip().replace(\"\\n\", \" \")\n",
        "        print(f\"üìÑ {titulo} ‚Äì Fragmento {i+1}:\")\n",
        "        print(f\"\\\"{fragmento[:100]}...\\\"\\n\")"
      ],
      "metadata": {
        "id": "BR7t5aSz81ls"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Test RAG"
      ],
      "metadata": {
        "id": "VzoQp08kcSAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta_usuario(\"¬øQui√©n fue Fernando Ra√∫l Klein?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww_qd2F38797",
        "outputId": "12b5fedb-c4ad-406b-c40d-8702519f44f9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: \n",
            "¬øQui√©n fue Fernando Ra√∫l Klein?\n",
            "Respuesta:\n",
            "Fernando Ra√∫l Klein es el autor de la tesis titulada \"Historia y memoria de la\n",
            "inmigraci√≥n jud√≠a sefard√≠ al Uruguay. An√°lisis de sus pr√°cticas sociales y modos\n",
            "de inserci√≥n en la sociedad uruguaya. 1908-1937\". Esta tesis fue presentada para\n",
            "la obtenci√≥n del grado de Doctor en Historia en la Universidad Nacional de La\n",
            "Plata.\n",
            "Tiempo de computo: 4.60 segundos\n",
            "\n",
            "\n",
            "Documentos Fuente:\n",
            "üìÑ Sin t√≠tulo ‚Äì Fragmento 3601:\n",
            "\"Klein, Fernando Ra√∫l  Historia y memoria de lainmigraci√≥n jud√≠a sefard√≠ alUruguay  Tesis presentada ...\"\n",
            "\n",
            "üìÑ Historia y memoria de la inmigracioÃÅn judiÃÅa sefardiÃÅ al Uruguay ‚Äì Fragmento 3601:\n",
            "\"Klein, Fernando Ra√∫l  Historia y memoria de lainmigraci√≥n jud√≠a sefard√≠ alUruguay  Tesis presentada ...\"\n",
            "\n",
            "üìÑ Historia y memoria de la inmigracioÃÅn judiÃÅa sefardiÃÅ al Uruguay ‚Äì Fragmento 3601:\n",
            "\"Klein, Fernando Ra√∫l  Historia y memoria de lainmigraci√≥n jud√≠a sefard√≠ alUruguay  Tesis presentada ...\"\n",
            "\n",
            "üìÑ Sin t√≠tulo ‚Äì Fragmento 3601:\n",
            "\"Klein, Fernando Ra√∫l  Historia y memoria de lainmigraci√≥n jud√≠a sefard√≠ alUruguay  Tesis presentada ...\"\n",
            "\n",
            "üìÑ pasado-y-memoria-revista-de-historia-contemporanea-num-10-los-politicos-europeos-y-napoleon-european-politicians-and-napoleon-2011-996637 ‚Äì Fragmento 3601:\n",
            "\"327  328  Autores / Authors  memoria de la dictadura en Iberoam√©rica (Buenos Aires, 2010) y Pol√≠tica...\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta_usuario('¬øCual fue la distribucion regional de la emigracion espa√±ola hacia latinoamerica en los anos 1965-70?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSh2JKRHN2lR",
        "outputId": "d532a375-b4d8-4a31-f554-7a94949b02e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: \n",
            "¬øCual fue la distribucion regional de la emigracion espa√±ola hacia latinoamerica en los anos 1965-70?\n",
            "Respuesta:\n",
            "El contexto no proporciona informaci√≥n espec√≠fica sobre la distribuci√≥n regional\n",
            "de la emigraci√≥n espa√±ola hacia Latinoam√©rica en los a√±os 1965-70.\n",
            "Tiempo de computo: 4.20 segundos\n",
            "\n",
            "\n",
            "Documentos Fuente:\n",
            "üìÑ Sin t√≠tulo ‚Äì Fragmento 3601:\n",
            "\"211  FIGURA 1. Evoluci√≥n anual de la emigraci√≥n espa√±ola asistida a Latinoam√©rica, 1968-1990.  CUADR...\"\n",
            "\n",
            "üìÑ Sin t√≠tulo ‚Äì Fragmento 3601:\n",
            "\"211  FIGURA 1. Evoluci√≥n anual de la emigraci√≥n espa√±ola asistida a Latinoam√©rica, 1968-1990.  CUADR...\"\n",
            "\n",
            "üìÑ la-emigracin-espaola-asistida-a-latinoamrica-19681990-0 ‚Äì Fragmento 3601:\n",
            "\"211  FIGURA 1. Evoluci√≥n anual de la emigraci√≥n espa√±ola asistida a Latinoam√©rica, 1968-1990.  CUADR...\"\n",
            "\n",
            "üìÑ la-emigracin-espaola-asistida-a-latinoamrica-19681990-0 ‚Äì Fragmento 3601:\n",
            "\"211  FIGURA 1. Evoluci√≥n anual de la emigraci√≥n espa√±ola asistida a Latinoam√©rica, 1968-1990.  CUADR...\"\n",
            "\n",
            "üìÑ Sin t√≠tulo ‚Äì Fragmento 3601:\n",
            "\"ran cierta relevancia a partir de 1981, caso de Colombia, Ecuador o Per√∫ (Cuadro III). Otra de las c...\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Descargar vector database"
      ],
      "metadata": {
        "id": "dgT2yXKTgF8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "# Comprimir en un archivo ZIP\n",
        "shutil.make_archive(\"chroma_ve\", 'zip', ruta_vector_embeddings)\n",
        "# Descargar embedings vector database\n",
        "files.download(\"chroma_ve.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-eA7k3oEgAAA",
        "outputId": "40ba5f26-c57c-4b86-8e2c-71d645e99168"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e43c2f1c-9583-4ced-9775-5c620b582f01\", \"chroma_ve.zip\", 147249955)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}